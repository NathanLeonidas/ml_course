Logdir : logs\FancyCNN_2
## Command 
C:\Users\nlewy\Desktop\pytorch_lab\src\torchtmpl\main.py config.yaml train

 Config : {'data': {'root_dir': './data/', 'batch_size': 128, 'num_workers': 4, 'valid_ratio': 0.2}, 'nepochs': 20, 'logging': {'logdir': './logs'}, 'model': {'class': 'FancyCNN'}} 

## Summary of the model architecture
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
FancyCNN                                 [10, 101]                 --
├─Sequential: 1-1                        [10, 384, 1, 1]           --
│    └─Conv2d: 2-1                       [10, 3, 128, 128]         84
│    └─ReLU: 2-2                         [10, 3, 128, 128]         --
│    └─BatchNorm2d: 2-3                  [10, 3, 128, 128]         6
│    └─Conv2d: 2-4                       [10, 6, 128, 128]         168
│    └─ReLU: 2-5                         [10, 6, 128, 128]         --
│    └─BatchNorm2d: 2-6                  [10, 6, 128, 128]         12
│    └─Conv2d: 2-7                       [10, 6, 64, 64]           150
│    └─ReLU: 2-8                         [10, 6, 64, 64]           --
│    └─BatchNorm2d: 2-9                  [10, 6, 64, 64]           12
│    └─Conv2d: 2-10                      [10, 6, 64, 64]           330
│    └─ReLU: 2-11                        [10, 6, 64, 64]           --
│    └─BatchNorm2d: 2-12                 [10, 6, 64, 64]           12
│    └─Conv2d: 2-13                      [10, 12, 64, 64]          660
│    └─ReLU: 2-14                        [10, 12, 64, 64]          --
│    └─BatchNorm2d: 2-15                 [10, 12, 64, 64]          24
│    └─Conv2d: 2-16                      [10, 12, 32, 32]          588
│    └─ReLU: 2-17                        [10, 12, 32, 32]          --
│    └─BatchNorm2d: 2-18                 [10, 12, 32, 32]          24
│    └─Conv2d: 2-19                      [10, 12, 32, 32]          1,308
│    └─ReLU: 2-20                        [10, 12, 32, 32]          --
│    └─BatchNorm2d: 2-21                 [10, 12, 32, 32]          24
│    └─Conv2d: 2-22                      [10, 24, 32, 32]          2,616
│    └─ReLU: 2-23                        [10, 24, 32, 32]          --
│    └─BatchNorm2d: 2-24                 [10, 24, 32, 32]          48
│    └─Conv2d: 2-25                      [10, 24, 16, 16]          2,328
│    └─ReLU: 2-26                        [10, 24, 16, 16]          --
│    └─BatchNorm2d: 2-27                 [10, 24, 16, 16]          48
│    └─Conv2d: 2-28                      [10, 24, 16, 16]          5,208
│    └─ReLU: 2-29                        [10, 24, 16, 16]          --
│    └─BatchNorm2d: 2-30                 [10, 24, 16, 16]          48
│    └─Conv2d: 2-31                      [10, 48, 16, 16]          10,416
│    └─ReLU: 2-32                        [10, 48, 16, 16]          --
│    └─BatchNorm2d: 2-33                 [10, 48, 16, 16]          96
│    └─Conv2d: 2-34                      [10, 48, 8, 8]            9,264
│    └─ReLU: 2-35                        [10, 48, 8, 8]            --
│    └─BatchNorm2d: 2-36                 [10, 48, 8, 8]            96
│    └─Conv2d: 2-37                      [10, 48, 8, 8]            20,784
│    └─ReLU: 2-38                        [10, 48, 8, 8]            --
│    └─BatchNorm2d: 2-39                 [10, 48, 8, 8]            96
│    └─Conv2d: 2-40                      [10, 96, 8, 8]            41,568
│    └─ReLU: 2-41                        [10, 96, 8, 8]            --
│    └─BatchNorm2d: 2-42                 [10, 96, 8, 8]            192
│    └─Conv2d: 2-43                      [10, 96, 4, 4]            36,960
│    └─ReLU: 2-44                        [10, 96, 4, 4]            --
│    └─BatchNorm2d: 2-45                 [10, 96, 4, 4]            192
│    └─Conv2d: 2-46                      [10, 96, 4, 4]            83,040
│    └─ReLU: 2-47                        [10, 96, 4, 4]            --
│    └─BatchNorm2d: 2-48                 [10, 96, 4, 4]            192
│    └─Conv2d: 2-49                      [10, 192, 4, 4]           166,080
│    └─ReLU: 2-50                        [10, 192, 4, 4]           --
│    └─BatchNorm2d: 2-51                 [10, 192, 4, 4]           384
│    └─Conv2d: 2-52                      [10, 192, 2, 2]           147,648
│    └─ReLU: 2-53                        [10, 192, 2, 2]           --
│    └─BatchNorm2d: 2-54                 [10, 192, 2, 2]           384
│    └─Conv2d: 2-55                      [10, 192, 2, 2]           331,968
│    └─ReLU: 2-56                        [10, 192, 2, 2]           --
│    └─BatchNorm2d: 2-57                 [10, 192, 2, 2]           384
│    └─Conv2d: 2-58                      [10, 384, 2, 2]           663,936
│    └─ReLU: 2-59                        [10, 384, 2, 2]           --
│    └─BatchNorm2d: 2-60                 [10, 384, 2, 2]           768
│    └─Conv2d: 2-61                      [10, 384, 1, 1]           590,208
│    └─ReLU: 2-62                        [10, 384, 1, 1]           --
│    └─BatchNorm2d: 2-63                 [10, 384, 1, 1]           768
├─AdaptiveAvgPool2d: 1-2                 [10, 384, 1, 1]           --
├─Linear: 1-3                            [10, 101]                 38,885
==========================================================================================
Total params: 2,158,007
Trainable params: 2,158,007
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 323.82
==========================================================================================
Input size (MB): 1.97
Forward/backward pass size (MB): 54.63
Params size (MB): 8.63
Estimated Total Size (MB): 65.23
==========================================================================================

## Loss

CrossEntropyLoss()

## Datasets : 
Train : WrappedDataset(dataset=<torch.utils.data.dataset.Subset object at 0x00000249807C3620>, transform=Compose(
      ToImage()
      GrayToRGB()
      Resize(size=[128], interpolation=InterpolationMode.BILINEAR, antialias=True)
      RandomCrop(size=(128, 128), pad_if_needed=False, fill=0, padding_mode=constant)
      ToDtype(scale=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
      RandomHorizontalFlip(p=0.5)
      RandomPerspective(p=0.5, distortion_scale=0.5, interpolation=InterpolationMode.BILINEAR, fill=0)
))
Validation : WrappedDataset(dataset=<torch.utils.data.dataset.Subset object at 0x00000249FB547250>, transform=Compose(
      ToImage()
      GrayToRGB()
      Resize(size=[128], interpolation=InterpolationMode.BILINEAR, antialias=True)
      RandomCrop(size=(128, 128), pad_if_needed=False, fill=0, padding_mode=constant)
      ToDtype(scale=True)
      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], inplace=False)
))